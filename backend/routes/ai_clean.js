import express from 'express';
import multer from 'multer';
import OpenAI from 'openai';

const router = express.Router();

// API Key espec√≠fica para Video Correcci√≥n IA
const OPENAI_API_KEY = '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';
const MODEL = process.env.OPENAI_VISION_MODEL || 'gpt-4o-mini';

// Cliente OpenAI espec√≠fico para este m√≥dulo
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

// Prompt del sistema para an√°lisis biomec√°nico
const SYSTEM_PROMPT = `Eres un analista biomec√°nico experto y entrenador personal certificado con m√°s de 15 a√±os de experiencia. Tu especialidad es el an√°lisis de t√©cnica de ejercicios y correcci√≥n postural.

INSTRUCCIONES:
1. Analiza la(s) imagen(es) proporcionada(s) con enfoque en biomec√°nica y t√©cnica
2. Identifica errores t√©cnicos, desviaciones posturales y compensaciones
3. Proporciona correcciones espec√≠ficas y progresivas
4. Adapta tus recomendaciones al perfil del usuario (nivel, lesiones, objetivos)
5. Mant√©n un tono profesional pero accesible

RESPONDE SIEMPRE EN FORMATO JSON CON ESTA ESTRUCTURA EXACTA:
{
  "ejercicio_detectado": "nombre del ejercicio identificado",
  "fase_movimiento": "exc√©ntrica/conc√©ntrica/isom√©trica/posici√≥n inicial/transici√≥n",
  "puntuacion_general": 85,
  "confidence": "high/medium/low",
  "errores": [
    {
      "categoria": "postural/t√©cnico/rango_movimiento/timing",
      "descripcion": "descripci√≥n espec√≠fica del error",
      "severidad": "leve/moderada/severa",
      "zona_afectada": "parte del cuerpo espec√≠fica",
      "impacto": "consecuencias potenciales"
    }
  ],
  "aspectos_correctos": [
    "lista de aspectos que se ejecutan correctamente"
  ],
  "correcciones": [
    {
      "prioridad": "alta/media/baja",
      "accion": "correcci√≥n espec√≠fica paso a paso",
      "explicacion": "fundamento biomec√°nico",
      "cue_verbal": "instrucci√≥n concisa para el usuario"
    }
  ],
  "adaptaciones_perfil": {
    "para_nivel": "sugerencias espec√≠ficas seg√∫n nivel del usuario",
    "consideraciones_lesiones": "adaptaciones por lesiones/limitaciones",
    "progresion": "siguiente paso en la progresi√≥n del ejercicio"
  },
  "observaciones_adicionales": "comentarios generales y contexto"
}

CRITERIOS DE EVALUACI√ìN:
- Alineaci√≥n corporal y postura
- Rango de movimiento y control
- Activaci√≥n muscular aparente
- Estabilidad y equilibrio
- T√©cnica respiratoria (si es visible)
- Progresi√≥n y regresi√≥n apropiada`;

// Funci√≥n helper para parsear JSON de manera segura
function safeJSON(v) { 
  try { 
    return v ? JSON.parse(v) : null; 
  } catch { 
    return null; 
  } 
}

// Configurar multer para manejar archivos en memoria
const upload = multer({
  storage: multer.memoryStorage(),
  limits: {
    fileSize: 10 * 1024 * 1024, // 10MB m√°ximo
  },
  fileFilter: (req, file, cb) => {
    // Permitir solo im√°genes
    if (file.mimetype.startsWith('image/')) {
      cb(null, true);
    } else {
      cb(new Error('Solo se permiten archivos de imagen'), false);
    }
  }
});

/**
 * GET /api/ai/test
 * Endpoint de prueba para verificar conectividad
 */
router.get('/test', (req, res) => {
  res.json({
    status: 'OK',
    message: 'API de IA funcionando correctamente',
    timestamp: new Date().toISOString(),
    model: MODEL,
    hasApiKey: !!OPENAI_API_KEY,
    apiKeyPreview: OPENAI_API_KEY ? `${OPENAI_API_KEY.slice(0, 10)}...` : 'No configurada'
  });
});

/**
 * POST /api/ai/advanced-correction
 * An√°lisis avanzado de t√©cnica de ejercicio usando IA
 * Acepta 1 'frame' y m√∫ltiples 'images'
 */
router.post('/advanced-correction', 
  upload.fields([
    { name: 'frame', maxCount: 1 }, 
    { name: 'images', maxCount: 8 }
  ]), 
  async (req, res) => {
    try {
      const exerciseId = (req.body.exerciseId || 'desconocido').toString();
      const userId = (req.body.userId || 'me').toString();

      const perfilUsuario = safeJSON(req.body.perfilUsuario);
      const contextoSesion = safeJSON(req.body.contextoSesion);
      const landmarks = safeJSON(req.body.landmarks);

      // Recopilar todos los buffers de imagen
      const buffers = [
        ...(req.files?.frame || []).map(f => f.buffer),
        ...(req.files?.images || []).map(f => f.buffer)
      ];

      if (buffers.length === 0) {
        return res.status(400).json({ 
          error: 'Falta al menos una imagen (frame o images[])',
          code: 'NO_IMAGE'
        });
      }

      // Convertir todas las im√°genes a base64
      const b64List = buffers.map(b => b.toString('base64'));
      
      // Preparar payload del usuario
      const userPayload = {
        ejercicio: exerciseId,
        perfil_usuario: perfilUsuario ?? null,
        contexto_sesion: contextoSesion ?? null,
        landmarks: landmarks ?? null,
        imagenes: b64List.map((_, i) => `frame_${i + 1}.jpg`)
      };

      // Preparar contenido para OpenAI
      const userContent = [
        { type: 'text', text: JSON.stringify(userPayload) },
        ...b64List.map(b64 => ({
          type: 'image_url',
          image_url: { url: `data:image/jpeg;base64,${b64}` }
        }))
      ];

      // Log para debugging
      if (process.env.NODE_ENV === 'development') {
        console.log('ü§ñ Iniciando an√°lisis IA:', {
          exerciseId,
          userId,
          imageCount: buffers.length,
          hasProfile: !!perfilUsuario,
          hasContext: !!contextoSesion,
          hasLandmarks: !!landmarks
        });
      }

      // Llamada a OpenAI Vision con JSON mode
      const completion = await openai.chat.completions.create({
        model: MODEL,
        messages: [
          { role: 'system', content: SYSTEM_PROMPT },
          { role: 'user', content: userContent }
        ],
        response_format: { type: 'json_object' },
        max_tokens: 1500,
        temperature: 0.3
      });

      const text = completion.choices?.[0]?.message?.content || '{}';
      const json = safeJSON(text) ?? { raw: text };

      // Enriquecer respuesta con metadatos
      const enrichedResult = {
        ...json,
        metadata: {
          exerciseId,
          userId,
          timestamp: new Date().toISOString(),
          model: MODEL,
          imageCount: buffers.length,
          totalSize: buffers.reduce((sum, buf) => sum + buf.length, 0),
          confidence: json.confidence || 'medium'
        }
      };

      // Log del resultado
      if (process.env.NODE_ENV === 'development') {
        console.log('‚úÖ An√°lisis IA completado:', {
          exerciseId,
          confidence: enrichedResult.metadata.confidence,
          errorsDetected: json.errores?.length || 0,
          correctionsCount: json.correcciones?.length || 0
        });
      }

      res.json(enrichedResult);

    } catch (err) {
      console.error('Error en an√°lisis avanzado IA:', err);
      
      // Manejo espec√≠fico de errores de OpenAI
      if (err.code === 'invalid_api_key') {
        return res.status(401).json({
          error: 'Clave de API de OpenAI inv√°lida',
          code: 'INVALID_API_KEY'
        });
      }

      if (err.code === 'insufficient_quota') {
        return res.status(429).json({
          error: 'Cuota de OpenAI agotada',
          code: 'QUOTA_EXCEEDED'
        });
      }

      res.status(500).json({ 
        error: err?.message || 'Error interno',
        code: 'INTERNAL_ERROR'
      });
    }
  }
);

export default router;
